

===== /Users/ivanvasilev/Desktop/code-folder-local/servers-validation/open-strategy-mcp-server/.actor =====



===== /Users/ivanvasilev/Desktop/code-folder-local/servers-validation/open-strategy-mcp-server/osp_marketing_tools/.dockerignore =====

# .dockerignore file for the project

# Ignore version control files
.git/
.gitignore

# Ignore Python cache and compiled files
__pycache__/
*.pyc
*.pyo
.pytest_cache/
.coverage

# Ignore IDE and editor files
.idea/
.vscode/
*.swp
*.swo

# Ignore build and test artifacts
dist/
build/
out/
test/
tests/
*_test.go

# Ignore environment and secret files
.env*
*.env
*.pem
*.key
*.crt
config.local.*
*.local.yml

# Ignore documentation and temporary files
docs/
*.md
README*
tmp/
temp/
*.tmp
.local/
local/

# Ignore Docker-related files
Dockerfile*
docker-compose*

# Ignore project-specific files
uv.lock


===== /Users/ivanvasilev/Desktop/code-folder-local/servers-validation/open-strategy-mcp-server/osp_marketing_tools/.gitignore =====

# Byte-compiled / optimized / DLL files
__pycache__/
*.py[cod]
*$py.class

# C extensions
*.so

# Distribution / packaging
dist/
build/
*.egg-info/
*.egg

# Virtual environments
venv/
env/
ENV/
.env/
.venv/

# IDE specific files
.idea/
.vscode/
*.swp
*.swo
.project
.pydevproject
.settings/

# Jupyter Notebook
.ipynb_checkpoints
*.ipynb

# Testing
.coverage
htmlcov/
.tox/
.pytest_cache/
nosetests.xml
coverage.xml

# Documentation
docs/_build/
site/

# Logs and databases
*.log
*.sqlite
*.db

# Local development settings
.env
.env.local
.env.*.local

# OS generated files
.DS_Store
.DS_Store?
._*
.Spotlight-V100
.Trashes
ehthumbs.db
Thumbs.db

# mypy
.mypy_cache/
.dmypy.json
dmypy.json

# pipenv
Pipfile.lock

# poetry
poetry.lock


===== /Users/ivanvasilev/Desktop/code-folder-local/servers-validation/open-strategy-mcp-server/osp_marketing_tools/.git =====



===== /Users/ivanvasilev/Desktop/code-folder-local/servers-validation/open-strategy-mcp-server/osp_marketing_tools/src/osp_marketing_tools/server.py =====

"""OSP Marketing Tools server implementation."""

import os
import asyncio
import json
from typing import Dict, Any, List

from mcp.server.fastmcp import FastMCP
from mcp.types import TextContent

def get_logger(name: str):
    import logging
    logger = logging.getLogger(name)
    return logger

logger = get_logger(__name__)

# Create server instance using FastMCP
mcp = FastMCP("osp_marketing_tools")

@mcp.tool()
async def health_check() -> dict:
    """Check if the server is running and can access its resources"""
    return {
        "status": "healthy",
        "resources": ["osp://marketing-tools"],
        "version": "0.1.0"
    }

@mcp.tool()
async def get_editing_codes() -> dict:
    """Get the Open Strategy Partners (OSP) editing codes documentation and usage protocol for editing texts."""
    script_dir = os.path.dirname(os.path.abspath(__file__))
    try:
        with open(os.path.join(script_dir, 'codes-llm.md'), 'r') as f:
            content = f.read()
            return {
                "success": True,
                "data": {
                    "content": content
                }
            }
    except FileNotFoundError:
        return {
            "success": False,
            "error": "Required file 'codes-llm.md' not found in script directory"
        }

@mcp.tool()
async def get_writing_guide() -> dict:
    """Get the Open Strategy Partners (OSP) writing guide and usage protocol for editing texts."""
    script_dir = os.path.dirname(os.path.abspath(__file__))
    try:
        with open(os.path.join(script_dir, 'guide-llm.md'), 'r') as f:
            content = f.read()
            return {
                "success": True,
                "data": {
                    "content": content
                }
            }
    except FileNotFoundError:
        return {
            "success": False,
            "error": "Required file 'writing-llm.md' not found in script directory"
        }   

@mcp.tool()
async def get_meta_guide() -> dict:
    """Get the Open Strategy Partners (OSP) Web Content Meta Information Generation System (titles, meta-titles, slugs)."""
    script_dir = os.path.dirname(os.path.abspath(__file__))
    try:
        with open(os.path.join(script_dir, 'meta-llm.md'), 'r') as f:
            content = f.read()
            return {
                "success": True,
                "data": {
                    "content": content
                }
            }
    except FileNotFoundError:
        return {
            "success": False,
            "error": "Required file 'meta-llm.md' not found in script directory"
        }

@mcp.tool()
async def get_value_map_positioning_guide() -> dict:
    """Get the Open Strategy Partners (OSP) Product Communications Value Map Generation System for Product Positioning (value cases, feature extraction, taglines)."""
    script_dir = os.path.dirname(os.path.abspath(__file__))
    try:
        with open(os.path.join(script_dir, 'product-value-map-llm.md'), 'r') as f:
            content = f.read()
            return {
                "success": True,
                "data": {
                    "content": content
                }
            }
    except FileNotFoundError:
        return {
            "success": False,
            "error": "Required file 'product-value-map-llm.md' not found in script directory"
        }

@mcp.tool()
async def get_on_page_seo_guide() -> dict:
    """Get the Open Strategy Partners (OSP) On-Page SEO Optimization Guide."""
    script_dir = os.path.dirname(os.path.abspath(__file__))
    try:
        with open(os.path.join(script_dir, 'on-page-seo-guide.md'), 'r') as f:
            content = f.read()
            return {
                "success": True,
                "data": {
                    "content": content
                }
            }
    except FileNotFoundError:
        return {
            "success": False,
            "error": "Required file 'on-page-seo-guide.md' not found in script directory"
        }


def main() -> None:
    """Run the MCP server."""
    try:
        mcp.run()
    except Exception as e:
        print(f"Error starting server: {str(e)}")
        raise

if __name__ == "__main__":
    main()


===== /Users/ivanvasilev/Desktop/code-folder-local/servers-validation/open-strategy-mcp-server/osp_marketing_tools/src/osp_marketing_tools/__init__.py =====

"""OSP Marketing Tools package."""

===== /Users/ivanvasilev/Desktop/code-folder-local/servers-validation/open-strategy-mcp-server/.dockerignore =====

.git
.mise.toml
.nvim.lua
storage

# The rest is copied from https://github.com/github/gitignore/blob/main/Python.gitignore

# Byte-compiled / optimized / DLL files
__pycache__/
*.py[cod]
*$py.class

# C extensions
*.so

# Distribution / packaging
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
share/python-wheels/
*.egg-info/
.installed.cfg
*.egg
MANIFEST

# PyInstaller
#  Usually these files are written by a python script from a template
#  before PyInstaller builds the exe, so as to inject date/other infos into it.
*.manifest
*.spec

# Installer logs
pip-log.txt
pip-delete-this-directory.txt

# Unit test / coverage reports
htmlcov/
.tox/
.nox/
.coverage
.coverage.*
.cache
nosetests.xml
coverage.xml
*.cover
*.py,cover
.hypothesis/
.pytest_cache/
cover/

# Translations
*.mo
*.pot

# Django stuff:
*.log
local_settings.py
db.sqlite3
db.sqlite3-journal

# Flask stuff:
instance/
.webassets-cache

# Scrapy stuff:
.scrapy

# Sphinx documentation
docs/_build/

# PyBuilder
.pybuilder/
target/

# Jupyter Notebook
.ipynb_checkpoints

# IPython
profile_default/
ipython_config.py

# pyenv
#   For a library or package, you might want to ignore these files since the code is
#   intended to run in multiple environments; otherwise, check them in:
.python-version

# pdm
#   Similar to Pipfile.lock, it is generally recommended to include pdm.lock in version control.
#pdm.lock
#   pdm stores project-wide configurations in .pdm.toml, but it is recommended to not include it
#   in version control.
#   https://pdm.fming.dev/latest/usage/project/#working-with-version-control
.pdm.toml
.pdm-python
.pdm-build/

# PEP 582; used by e.g. github.com/David-OConnor/pyflow and github.com/pdm-project/pdm
__pypackages__/

# Celery stuff
celerybeat-schedule
celerybeat.pid

# SageMath parsed files
*.sage.py

# Environments
.env
.venv
env/
venv/
ENV/
env.bak/
venv.bak/

# Spyder project settings
.spyderproject
.spyproject

# Rope project settings
.ropeproject

# mkdocs documentation
/site

# mypy
.mypy_cache/
.dmypy.json
dmypy.json

# Pyre type checker
.pyre/

# pytype static type analyzer
.pytype/

# Cython debug symbols
cython_debug/

# PyCharm
#  JetBrains specific template is maintained in a separate JetBrains.gitignore that can
#  be found at https://github.com/github/gitignore/blob/main/Global/JetBrains.gitignore
#  and can be added to the global gitignore or merged into this file.  For a more nuclear
#  option (not recommended) you can uncomment the following to ignore the entire idea folder.
.idea/

# Visual Studio Code
#  Ignores the folder created by VS Code when changing workspace settings, doing debugger
#  configuration, etc. Can be commented out to share Workspace Settings within a team
.vscode

# Zed editor
#  Ignores the folder created when setting Project Settings in the Zed editor. Can be commented out
#  to share Project Settings within a team
.zed


===== /Users/ivanvasilev/Desktop/code-folder-local/servers-validation/open-strategy-mcp-server/.gitignore =====

.mise.toml
.nvim.lua
storage

# The rest is copied from https://github.com/github/gitignore/blob/main/Python.gitignore

# Byte-compiled / optimized / DLL files
__pycache__/
*.py[cod]
*$py.class

# C extensions
*.so

# Distribution / packaging
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
share/python-wheels/
*.egg-info/
.installed.cfg
*.egg
MANIFEST

# PyInstaller
#  Usually these files are written by a python script from a template
#  before PyInstaller builds the exe, so as to inject date/other infos into it.
*.manifest
*.spec

# Installer logs
pip-log.txt
pip-delete-this-directory.txt

# Unit test / coverage reports
htmlcov/
.tox/
.nox/
.coverage
.coverage.*
.cache
nosetests.xml
coverage.xml
*.cover
*.py,cover
.hypothesis/
.pytest_cache/
cover/

# Translations
*.mo
*.pot

# Django stuff:
*.log
local_settings.py
db.sqlite3
db.sqlite3-journal

# Flask stuff:
instance/
.webassets-cache

# Scrapy stuff:
.scrapy

# Sphinx documentation
docs/_build/

# PyBuilder
.pybuilder/
target/

# Jupyter Notebook
.ipynb_checkpoints

# IPython
profile_default/
ipython_config.py

# pyenv
#   For a library or package, you might want to ignore these files since the code is
#   intended to run in multiple environments; otherwise, check them in:
.python-version

# pdm
#   Similar to Pipfile.lock, it is generally recommended to include pdm.lock in version control.
#pdm.lock
#   pdm stores project-wide configurations in .pdm.toml, but it is recommended to not include it
#   in version control.
#   https://pdm.fming.dev/latest/usage/project/#working-with-version-control
.pdm.toml
.pdm-python
.pdm-build/

# PEP 582; used by e.g. github.com/David-OConnor/pyflow and github.com/pdm-project/pdm
__pypackages__/

# Celery stuff
celerybeat-schedule
celerybeat.pid

# SageMath parsed files
*.sage.py

# Environments
.env
.venv
env/
venv/
ENV/
env.bak/
venv.bak/

# Spyder project settings
.spyderproject
.spyproject

# Rope project settings
.ropeproject

# mkdocs documentation
/site

# mypy
.mypy_cache/
.dmypy.json
dmypy.json

# Pyre type checker
.pyre/

# pytype static type analyzer
.pytype/

# Cython debug symbols
cython_debug/

# PyCharm
#  JetBrains specific template is maintained in a separate JetBrains.gitignore that can
#  be found at https://github.com/github/gitignore/blob/main/Global/JetBrains.gitignore
#  and can be added to the global gitignore or merged into this file.  For a more nuclear
#  option (not recommended) you can uncomment the following to ignore the entire idea folder.
.idea/

# Visual Studio Code
#  Ignores the folder created by VS Code when changing workspace settings, doing debugger
#  configuration, etc. Can be commented out to share Workspace Settings within a team
.vscode

# Zed editor
#  Ignores the folder created when setting Project Settings in the Zed editor. Can be commented out
#  to share Project Settings within a team
.zed

# Added by Apify CLI
node_modules


===== /Users/ivanvasilev/Desktop/code-folder-local/servers-validation/open-strategy-mcp-server/_stdio_client_help.py =====

python3 -m venv venv
from mcp.client.stdio import stdio_client
help(stdio_client)


===== /Users/ivanvasilev/Desktop/code-folder-local/servers-validation/open-strategy-mcp-server/src/mcp_gateway.py =====

# This file is copied from the latest Python MCP Actor template.
# Integrate or adapt as needed for your project.

import logging
from mcp import server, types
from .models import ServerType

logger = logging.getLogger('apify')


def create_mcp_gateway(server_type: ServerType, **kwargs) -> server.Server:
    """
    Factory for creating the MCP server instance based on the server type.
    """
    if server_type == ServerType.HTTP:
        logger.info('Creating HTTP MCP server...')
        # ...template logic for HTTP server...
        return server.Server(**kwargs)
    elif server_type == ServerType.STDIO:
        logger.info('Creating STDIO MCP server...')
        # ...template logic for STDIO server...
        return server.Server(**kwargs)
    else:
        raise ValueError(f'Unsupported server type: {server_type}')


===== /Users/ivanvasilev/Desktop/code-folder-local/servers-validation/open-strategy-mcp-server/src/server.py =====

"""Module implementing an MCP server that can be used to connect to stdio or SSE based MCP servers.

Heavily inspired by: https://github.com/sparfenyuk/mcp-proxy
"""

from __future__ import annotations

import contextlib
import logging
from typing import TYPE_CHECKING, Any

import httpx
import uvicorn
from mcp.client.session import ClientSession
from mcp.client.stdio import StdioServerParameters, stdio_client
from mcp.client.streamable_http import streamablehttp_client
from mcp.server.sse import SseServerTransport
from mcp.server.streamable_http_manager import StreamableHTTPSessionManager
from pydantic import ValidationError
from starlette.applications import Starlette
from starlette.middleware import Middleware
from starlette.middleware.base import BaseHTTPMiddleware
from starlette.responses import JSONResponse, RedirectResponse, Response
from starlette.routing import Mount, Route

from .event_store import InMemoryEventStore
from .models import RemoteServerParameters, ServerParameters, ServerType
from .proxy_server import create_proxy_server

if TYPE_CHECKING:
    from collections.abc import AsyncIterator, Awaitable, Callable

    from mcp.server import Server
    from starlette import types as st
    from starlette.requests import Request
    from starlette.types import Receive, Scope, Send

logger = logging.getLogger('apify')


class McpPathRewriteMiddleware(BaseHTTPMiddleware):
    """Add middleware to rewrite /mcp to /mcp/ to ensure consistent path handling.

    This is necessary so that Starlette does not return a 307 Temporary Redirect on the /mcp path,
    which would otherwise trigger the OAuth flow when the MCP server is deployed on the Apify platform.
    """

    async def dispatch(self, request: Request, call_next: Callable) -> Any:
        """Rewrite the request path."""
        if request.url.path == '/mcp':
            request.scope['path'] = '/mcp/'
            request.scope['raw_path'] = b'/mcp/'
        return await call_next(request)


class ProxyServer:
    """Main class implementing the proxy functionality using MCP SDK.

    This proxy runs a Starlette app that exposes /sse and /messages/ endpoints for legacy SSE transport,
            and a /mcp endpoint for Streamable HTTP transport.
    It then connects to stdio or remote MCP servers and forwards the messages to the client.

    The server can optionally charge for operations using a provided charging function.
    This is typically used in Apify Actors to charge users for MCP operations.
    The charging function should accept an event name and optional parameters.
    """

    def __init__(
        self,
        config: ServerParameters,
        host: str,
        port: int,
        server_type: ServerType,
        actor_charge_function: Callable[[str, int], Awaitable[Any]] | None = None,
    ) -> None:
        """Initialize the proxy server.

        Args:
            config: Server configuration (stdio or SSE parameters)
            host: Host to bind the server to
            port: Port to bind the server to
            server_type: Type of server to connect (stdio, SSE, or HTTP)
            actor_charge_function: Optional function to charge for operations.
                           Should accept (event_name: str, count: int).
                           Typically, Actor.charge in Apify Actors.
                           If None, no charging will occur.
        """
        self.server_type = server_type
        self.config = self._validate_config(self.server_type, config)
        self.path_sse: str = '/sse'
        self.path_message: str = '/message'
        self.host: str = host
        self.port: int = port
        self.actor_charge_function = actor_charge_function

    @staticmethod
    def _validate_config(client_type: ServerType, config: ServerParameters) -> ServerParameters | None:
        """Validate and return the appropriate server parameters."""
        try:
            match client_type:
                case ServerType.STDIO:
                    return StdioServerParameters.model_validate(config)
                case ServerType.SSE | ServerType.HTTP:
                    return RemoteServerParameters.model_validate(config)
                case _:
                    raise ValueError(f'Unsupported server type: {client_type}')
        except ValidationError as e:
            raise ValueError(f'Invalid server configuration: {e}') from e

    @staticmethod
    async def create_starlette_app(mcp_server: Server) -> Starlette:
        """Create a Starlette app (SSE server) that exposes /sse and /messages/ endpoints."""
        transport = SseServerTransport('/messages/')  # Only used for legacy SSE transport
        event_store = InMemoryEventStore()
        session_manager = StreamableHTTPSessionManager(
            app=mcp_server,
            event_store=event_store,  # Enable resume ability for Streamable HTTP connections
            json_response=False,
        )

        @contextlib.asynccontextmanager
        async def lifespan(_app: Starlette) -> AsyncIterator[None]:
            """Context manager for managing session manager lifecycle."""
            async with session_manager.run():
                logger.info('Application started with StreamableHTTP session manager!')
                try:
                    yield
                finally:
                    logger.info('Application shutting down...')

        async def handle_root(request: Request) -> st.Response:
            """Handle root endpoint."""
            # Handle Apify standby readiness probe
            if 'x-apify-container-server-readiness-probe' in request.headers:
                return Response(
                    content=b'ok',
                    media_type='text/plain',
                    status_code=200,
                )

            return JSONResponse(
                {
                    'status': 'running',
                    'type': 'mcp-server',
                    'transport': 'sse+streamable-http',
                    'endpoints': {
                        'sse': '/sse',
                        'messages': '/messages/',
                        'streamableHttp': '/mcp',
                    },
                }
            )

        async def handle_sse(request: st.Request) -> st.Response | None:
            """Handle incoming SSE requests."""
            try:
                async with transport.connect_sse(request.scope, request.receive, request._send) as streams:  # noqa: SLF001
                    init_options = mcp_server.create_initialization_options()
                    await mcp_server.run(streams[0], streams[1], init_options)
            except Exception as e:
                logger.exception('Error in SSE connection')
                return Response(status_code=500, content=str(e))
            finally:
                logger.info('SSE connection closed')
            # Add Response to prevent the None type error
            return Response(status_code=204)  # No content response

        async def handle_favicon(_request: Request) -> st.Response:
            """Handle favicon.ico requests by redirecting to Apify's favicon."""
            return RedirectResponse(url='https://apify.com/favicon.ico', status_code=301)

        async def handle_oauth_authorization_server(_request: Request) -> st.Response:
            """Handle OAuth authorization server well-known endpoint."""
            try:
                # Some MCP clients do not follow redirects, so we need to fetch the data and return it directly.
                async with httpx.AsyncClient() as client:
                    response = await client.get('https://api.apify.com/.well-known/oauth-authorization-server')
                    response.raise_for_status()
                    data = response.json()
                return JSONResponse(data, status_code=200)
            except Exception:
                logger.exception('Error fetching OAuth authorization server data')
                return JSONResponse({'error': 'Failed to fetch OAuth authorization server data'}, status_code=500)

        # ASGI handler for Streamable HTTP connections
        async def handle_streamable_http(scope: Scope, receive: Receive, send: Send) -> None:
            await session_manager.handle_request(scope, receive, send)

        return Starlette(
            debug=True,
            routes=[
                Route('/', endpoint=handle_root),
                Route('/favicon.ico', endpoint=handle_favicon, methods=['GET']),
                Route(
                    '/.well-known/oauth-authorization-server',
                    endpoint=handle_oauth_authorization_server,
                    methods=['GET'],
                ),
                Route('/sse', endpoint=handle_sse, methods=['GET']),
                Mount('/messages/', app=transport.handle_post_message),
                Mount('/mcp/', app=handle_streamable_http),
            ],
            lifespan=lifespan,
            middleware=[Middleware(McpPathRewriteMiddleware)],
        )

    async def _run_server(self, app: Starlette) -> None:
        """Run the Starlette app with uvicorn."""
        config_ = uvicorn.Config(app, host=self.host, port=self.port, log_level='info', access_log=True)
        server = uvicorn.Server(config_)
        await server.serve()

    async def start(self) -> None:
        """Start Starlette app and connect to stdio, Streamable HTTP, or SSE based MCP server."""
        logger.info(f'Starting MCP server with client type: {self.server_type} and config {self.config}')

        if self.server_type == ServerType.STDIO:
            # Pass the StdioServerParameters object directly
            async with (
                stdio_client(self.config) as (read_stream, write_stream),
                ClientSession(read_stream, write_stream) as session,
            ):
                mcp_server = await create_proxy_server(session, self.actor_charge_function)
                app = await self.create_starlette_app(mcp_server)
                await self._run_server(app)

        elif self.server_type == ServerType.SSE:
            # For SSE, keep using params (if needed)
            params: dict = (self.config and self.config.model_dump(exclude_unset=True)) or {}
            async with (
                stdio_client(**params) as (read_stream, write_stream),
                ClientSession(read_stream, write_stream) as session,
            ):
                mcp_server = await create_proxy_server(session, self.actor_charge_function)
                app = await self.create_starlette_app(mcp_server)
                await self._run_server(app)

        elif self.server_type == ServerType.HTTP:
            # HTTP streamable server needs to unpack three parameters
            async with (
                streamablehttp_client(**params) as (read_stream, write_stream, _),
                ClientSession(read_stream, write_stream) as session,
            ):
                mcp_server = await create_proxy_server(session, self.actor_charge_function)
                app = await self.create_starlette_app(mcp_server)
                await self._run_server(app)
        else:
            raise ValueError(f'Unknown server type: {self.server_type}')


===== /Users/ivanvasilev/Desktop/code-folder-local/servers-validation/open-strategy-mcp-server/src/models.py =====

from enum import Enum
from typing import Any, TypeAlias

import httpx
from mcp.client.stdio import StdioServerParameters
from pydantic import BaseModel, ConfigDict


class ServerType(str, Enum):
    """Type of server to connect."""

    STDIO = 'stdio'  # Connect to a stdio server
    SSE = 'sse'  # Connect to an SSE server
    HTTP = 'http'  # Connect to an HTTP server (Streamable HTTP)


class RemoteServerParameters(BaseModel):
    """Parameters for connecting to a Streamable HTTP or SSE-based MCP server.

    These parameters are passed either to the `streamable http_client` or `sse_client` from MCP SDK.

    Attributes:
        url: The URL of the HTTP or SSE server endpoint
        headers: Optional HTTP headers to include in the connection request
    """

    url: str
    headers: dict[str, Any] | None = None
    timeout: float = 60  # HTTP timeout for regular operations
    sse_read_timeout: float = 60 * 5  # Timeout for SSE read operations
    auth: httpx.Auth | None = None  # Optional HTTPX authentication handler
    model_config = ConfigDict(arbitrary_types_allowed=True)


# Type alias for server parameters
ServerParameters: TypeAlias = StdioServerParameters | RemoteServerParameters


===== /Users/ivanvasilev/Desktop/code-folder-local/servers-validation/open-strategy-mcp-server/src/__init__.py =====



===== /Users/ivanvasilev/Desktop/code-folder-local/servers-validation/open-strategy-mcp-server/src/proxy_server.py =====

"""Create an MCP server that proxies requests through an MCP client.

This server is created independent of any transport mechanism.
Source: https://github.com/sparfenyuk/mcp-proxy

The server can optionally charge for MCP operations using a provided charging function.
This is typically used in Apify Actors to charge users for different types of MCP operations
like tool calls, prompt operations, or resource access.
"""

from __future__ import annotations

import logging
from typing import TYPE_CHECKING, Any

from mcp import server, types

from .const import ChargeEvents

if TYPE_CHECKING:
    from collections.abc import Awaitable, Callable

    from mcp.client.session import ClientSession

logger = logging.getLogger('apify')


async def charge_mcp_operation(
    charge_function: Callable[[str, int], Awaitable[Any]] | None, event_name: ChargeEvents, count: int = 1
) -> None:
    """Charge for an MCP operation.

    Args:
        charge_function: Function to call for charging, or None if charging is disabled
        event_name: The type of event to charge for
        count: The number of times the event occurred (typically 1, but can be more)
    """
    if not charge_function:
        return

    try:
        await charge_function(event_name.value, count)
        logger.info(f'Charged for event {event_name.value}')
    except Exception:
        logger.exception(f'Failed to charge for event {event_name.value}')
        # Don't raise the exception - we want the operation to continue even if charging fails


async def create_proxy_server(  # noqa: PLR0915
    client_session: ClientSession,
    actor_charge_function: Callable[[str, int], Awaitable[Any]] | None = None,
) -> server.Server[object]:
    """Create a server instance from a remote app.

    Args:
        client_session: The MCP client session to proxy requests through
        actor_charge_function: Optional function to charge for operations.
                       Should accept (event_name: str, params: Optional[dict]).
                       Typically, Actor.charge in Apify Actors.
                       If None, no charging will occur.
    """
    logger.debug('Sending initialization request to remote MCP server...')
    response = await client_session.initialize()
    capabilities: types.ServerCapabilities = response.capabilities

    logger.debug('Configuring proxied MCP server...')
    app: server.Server = server.Server(name=response.serverInfo.name, version=response.serverInfo.version)

    if capabilities.prompts:
        logger.debug('Capabilities: adding Prompts...')


        async def _list_prompts(_: Any) -> types.ServerResult:
            # Charging for prompt listing disabled
            result = await client_session.list_prompts()
            return types.ServerResult(result)

        app.request_handlers[types.ListPromptsRequest] = _list_prompts


        async def _get_prompt(req: types.GetPromptRequest) -> types.ServerResult:
            # Charging for prompt get disabled
            result = await client_session.get_prompt(req.params.name, req.params.arguments)
            return types.ServerResult(result)

        app.request_handlers[types.GetPromptRequest] = _get_prompt

    if capabilities.resources:
        logger.debug('Capabilities: adding Resources...')


        async def _list_resources(_: Any) -> types.ServerResult:
            # Charging for resource listing disabled
            result = await client_session.list_resources()
            return types.ServerResult(result)

        app.request_handlers[types.ListResourcesRequest] = _list_resources

        async def _list_resource_templates(_: Any) -> types.ServerResult:
            result = await client_session.list_resource_templates()
            return types.ServerResult(result)

        app.request_handlers[types.ListResourceTemplatesRequest] = _list_resource_templates


        async def _read_resource(req: types.ReadResourceRequest) -> types.ServerResult:
            # Charging for resource read disabled
            result = await client_session.read_resource(req.params.uri)
            return types.ServerResult(result)

        app.request_handlers[types.ReadResourceRequest] = _read_resource

    if capabilities.logging:
        logger.debug('Capabilities: adding Logging...')

        async def _set_logging_level(req: types.SetLevelRequest) -> types.ServerResult:
            await client_session.set_logging_level(req.params.level)
            return types.ServerResult(types.EmptyResult())

        app.request_handlers[types.SetLevelRequest] = _set_logging_level

    if capabilities.resources:
        logger.debug('Capabilities: adding Resources...')

        async def _subscribe_resource(req: types.SubscribeRequest) -> types.ServerResult:
            await client_session.subscribe_resource(req.params.uri)
            return types.ServerResult(types.EmptyResult())

        app.request_handlers[types.SubscribeRequest] = _subscribe_resource

        async def _unsubscribe_resource(req: types.UnsubscribeRequest) -> types.ServerResult:
            await client_session.unsubscribe_resource(req.params.uri)
            return types.ServerResult(types.EmptyResult())

        app.request_handlers[types.UnsubscribeRequest] = _unsubscribe_resource

    if capabilities.tools:
        logger.debug('Capabilities: adding Tools...')


        async def _list_tools(_: Any) -> types.ServerResult:
            # Charging for tool listing disabled
            tools = await client_session.list_tools()
            return types.ServerResult(tools)

        app.request_handlers[types.ListToolsRequest] = _list_tools


        async def _call_tool(req: types.CallToolRequest) -> types.ServerResult:
            # Charging for tool call disabled
            try:
                result = await client_session.call_tool(req.params.name, (req.params.arguments or {}))
                return types.ServerResult(result)
            except Exception as e:
                return types.ServerResult(
                    types.CallToolResult(content=[types.TextContent(type='text', text=str(e))], isError=True),
                )

        app.request_handlers[types.CallToolRequest] = _call_tool

    async def _send_progress_notification(req: types.ProgressNotification) -> None:
        await client_session.send_progress_notification(
            req.params.progressToken,
            req.params.progress,
            req.params.total,
        )

    app.notification_handlers[types.ProgressNotification] = _send_progress_notification

    async def _complete(req: types.CompleteRequest) -> types.ServerResult:
        result = await client_session.complete(
            req.params.ref,
            req.params.argument.model_dump(),
        )
        return types.ServerResult(result)

    app.request_handlers[types.CompleteRequest] = _complete

    return app


===== /Users/ivanvasilev/Desktop/code-folder-local/servers-validation/open-strategy-mcp-server/src/event_store.py =====

# Source https://github.com/modelcontextprotocol/python-sdk/blob/3978c6e1b91e8830e82d97ab3c4e3b6559972021/examples/servers/simple-streamablehttp/mcp_simple_streamablehttp/event_store.py
"""In-memory event store for demonstrating resumability functionality.

This is a simple implementation intended for examples and testing,
not for production use where a persistent storage solution would be more appropriate.
"""

import logging
from collections import deque
from dataclasses import dataclass
from uuid import uuid4

from mcp.server.streamable_http import (
    EventCallback,
    EventId,
    EventMessage,
    EventStore,
    StreamId,
)
from mcp.types import JSONRPCMessage

logger = logging.getLogger(__name__)


@dataclass
class EventEntry:
    """Represents an event entry in the event store."""

    event_id: EventId
    stream_id: StreamId
    message: JSONRPCMessage


class InMemoryEventStore(EventStore):
    """Simple in-memory implementation of the EventStore interface for resumability.
    This is primarily intended for examples and testing, not for production use
    where a persistent storage solution would be more appropriate.

    This implementation keeps only the last N events per stream for memory efficiency.
    """  # noqa: D205

    def __init__(self, max_events_per_stream: int = 100):  # noqa: ANN204
        """Initialize the event store.

        Args:
            max_events_per_stream: Maximum number of events to keep per stream
        """
        self.max_events_per_stream = max_events_per_stream
        # for maintaining last N events per stream
        self.streams: dict[StreamId, deque[EventEntry]] = {}
        # event_id -> EventEntry for quick lookup
        self.event_index: dict[EventId, EventEntry] = {}

    async def store_event(self, stream_id: StreamId, message: JSONRPCMessage) -> EventId:
        """Stores an event with a generated event ID."""  # noqa: D401
        event_id = str(uuid4())
        event_entry = EventEntry(event_id=event_id, stream_id=stream_id, message=message)

        # Get or create deque for this stream
        if stream_id not in self.streams:
            self.streams[stream_id] = deque(maxlen=self.max_events_per_stream)

        # If deque is full, the oldest event will be automatically removed
        # We need to remove it from the event_index as well
        if len(self.streams[stream_id]) == self.max_events_per_stream:
            oldest_event = self.streams[stream_id][0]
            self.event_index.pop(oldest_event.event_id, None)

        # Add new event
        self.streams[stream_id].append(event_entry)
        self.event_index[event_id] = event_entry

        return event_id

    async def replay_events_after(
        self,
        last_event_id: EventId,
        send_callback: EventCallback,
    ) -> StreamId | None:
        """Replays events that occurred after the specified event ID."""
        if last_event_id not in self.event_index:
            logger.warning(f'Event ID {last_event_id} not found in store')
            return None

        # Get the stream and find events after the last one
        last_event = self.event_index[last_event_id]
        stream_id = last_event.stream_id
        stream_events = self.streams.get(last_event.stream_id, deque())

        # Events in deque are already in chronological order
        found_last = False
        for event in stream_events:
            if found_last:
                await send_callback(EventMessage(event.message, event.event_id))
            elif event.event_id == last_event_id:
                found_last = True

        return stream_id


===== /Users/ivanvasilev/Desktop/code-folder-local/servers-validation/open-strategy-mcp-server/src/main.py =====

"""Main entry point for the MCP Server Actor."""

import os

from apify import Actor

from .const import ChargeEvents
from .models import ServerType
from .server import ProxyServer


# Actor configuration
STANDBY_MODE = os.environ.get('APIFY_META_ORIGIN') == 'STANDBY'
HOST = '0.0.0.0'  # Required for container networking at Apify platform
PORT = (Actor.is_at_home() and int(os.environ.get('ACTOR_STANDBY_PORT') or '5001')) or 5001
SERVER_NAME = 'osp_marketing_tools'  # Name of the MCP server, update as needed

# EDIT THIS SECTION ------------------------------------------------------------
# Configuration constants - You need to override these values. You can also pass environment variables if needed.
from mcp.client.stdio import StdioServerParameters  # noqa: E402



# Set up to use the OSP Marketing Tools server as the default for Apify actorization
server_type = ServerType.STDIO
MCP_SERVER_PARAMS = StdioServerParameters(
    command='python',
    args=['-m', 'osp_marketing_tools.server'],
    env={'PYTHONPATH': 'osp_marketing_tools/src'},
)

# If you later want to use HTTP/SSE, uncomment and configure below:
# from .models import RemoteServerParameters  # noqa: ERA001
# server_type = ServerType.HTTP # or ServerType.SSE, depending on your server type # noqa: ERA001
# MCP_SERVER_PARAMS = RemoteServerParameters( # noqa: ERA001, RUF100
#     url='https://mcp.apify.com',  # noqa: ERA001
#     headers={'Authorization':  'Bearer YOUR-API-KEY'},  # Optional headers, e.g., for authentication  # noqa: ERA001
# )  # noqa: ERA001, RUF100
# ------------------------------------------------------------------------------


async def main() -> None:
    """Run the MCP Server Actor.

    This function:
    1. Initializes the Actor
    2. Charges for Actor startup
    3. Creates and starts the proxy server
    4. Configures charging for MCP operations using Actor.charge

    The proxy server will charge for different MCP operations like:
    - Tool calls
    - Prompt operations
    - Resource access
    - List operations

    Charging events are defined in .actor/pay_per_event.json
    """
    async with Actor:
        # Initialize and charge for Actor startup
        Actor.log.info('Starting MCP Server Actor')
        await Actor.charge(ChargeEvents.ACTOR_START.value)

        url = os.environ.get('ACTOR_STANDBY_URL', HOST)
        if not STANDBY_MODE:
            msg = (
                'Actor is not designed to run in the NORMAL mode. Use MCP server URL to connect to the server.\n'
                f'Connect to {url}/mcp to establish a connection.\n'
                'Learn more at https://mcp.apify.com/'
            )
            Actor.log.info(msg)
            await Actor.exit(status_message=msg)
            return

        try:
            # Create and start the server with charging enabled
            Actor.log.info('Starting MCP server')
            Actor.log.info('Add the following configuration to your MCP client to use Streamable HTTP transport:')
            Actor.log.info(
                f"""
                {{
                    "mcpServers": {{
                        "{SERVER_NAME}": {{
                            "url": "{url}/mcp",
                        }}
                    }}
                }}
                """
            )
            # Pass Actor.charge to enable charging for MCP operations
            # The proxy server will use this to charge for different operations
            proxy_server = ProxyServer(
                MCP_SERVER_PARAMS,
                HOST,
                PORT,
                server_type,
                actor_charge_function=Actor.charge
            )
            await proxy_server.start()
        except Exception as e:
            Actor.log.exception(f'Server failed to start: {e}')
            await Actor.exit()
            raise


===== /Users/ivanvasilev/Desktop/code-folder-local/servers-validation/open-strategy-mcp-server/src/__main__.py =====

import asyncio

from .main import main

# Execute the Actor entry point.
asyncio.run(main())


===== /Users/ivanvasilev/Desktop/code-folder-local/servers-validation/open-strategy-mcp-server/src/const.py =====

from enum import Enum


class ChargeEvents(str, Enum):
    """Event types for charging MCP operations.

    These events are used to charge users for different types of MCP operations
    when running as an Apify Actor. Each event corresponds to a specific operation
    that can be charged for, such as tool calls, resource access, or prompt operations.
    """

    ACTOR_START = 'actor-start'
    RESOURCE_LIST = 'resource-list'
    RESOURCE_READ = 'resource-read'
    PROMPT_LIST = 'prompt-list'
    PROMPT_GET = 'prompt-get'
    TOOL_LIST = 'tool-list'
    TOOL_CALL = 'tool-call'
